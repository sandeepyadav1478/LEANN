# âœ¨ Detailed Features

## ğŸ”¥ Core Features

- **ğŸ”„ Real-time Embeddings** - Eliminate heavy embedding storage with dynamic computation using optimized ZMQ servers and highly optimized search paradigm (overlapping and batching) with highly optimized embedding engine
- **ğŸ§  AST-Aware Code Chunking** - Intelligent code chunking that preserves semantic boundaries (functions, classes, methods) for Python, Java, C#, and TypeScript files
- **ğŸ“ˆ Scalable Architecture** - Handles millions of documents on consumer hardware; the larger your dataset, the more LEANN can save
- **ğŸ¯ Graph Pruning** - Advanced techniques to minimize the storage overhead of vector search to a limited footprint
- **ğŸ—ï¸ Pluggable Backends** - HNSW/FAISS (default), with optional DiskANN for large-scale deployments

## ğŸ“± Universal Ingestion & Formats

- **ğŸ“‘ Multi-Format Support**: Native handling of `.pdf`, `.txt`, `.md`, `.docx`, `.pptx`, `.xlsx`, and `.mm` (Mindmaps).
- **ğŸš€ Advanced PDF Pipeline**: Intelligent fallback chain featuring [PyMuPDF](https://github.com/pymupdf/PyMuPDF), [pypdf](https://github.com/py-pdf/pypdf), [pdfplumber](https://github.com/jsvine/pdfplumber), and [**Docling OCR**](https://github.com/docling-project/docling) (IBM Research) for high-fidelity document parsing.
- **ğŸ’¼ Office Document Extractors**: Structural awareness for Word ([python-docx](https://github.com/python-openxml/python-docx)), Excel ([openpyxl](https://github.com/ericgazoni/openpyxl)), and PowerPoint ([python-pptx](https://github.com/python-openxml/python-pptx)) preserving tables, slides, and sheets.
- **ğŸ§  Mindmap Parsing**: Hierarchical node extraction for [FreeMind](http://freemind.sourceforge.net/) and [Freeplane](https://www.freeplane.org/) (`.mm`) preserving semantic relationships in zettelkasten-like structures.
- **ğŸ“± Integrated Source Connectors**: Dedicated CLI commands for Apple Mail, Calendar, iMessage, WeChat, and more.

## âš¡ Performance & Scalability

- **ğŸš€ Instant CLI Discovery**: Optimized `leann list` and `leann remove` commands use intelligent scanning and size caching to respond in milliseconds, regardless of the number of registered projects.
- **ğŸ“ˆ Huge Vault Support**: Native **DiskANN** backend integration allows indexing terabytes of data (millions of chunks) without exceeding laptop RAM limits.
- **ğŸ§  Advanced Code Analysis**: AST-aware chunking supports complex logic retrieval. For large functions (e.g., algorithmic trading strategies), using `--ast-chunk-size 1000` ensures that entire logical blocks stay in the same context for the LLM.

## ğŸ› ï¸ Technical Highlights
- **ğŸ”„ Recompute Mode** - Highest accuracy scenarios while eliminating vector storage overhead
- **âš¡ Zero-copy Operations** - Minimize IPC overhead by transferring distances instead of embeddings
- **ğŸš€ High-throughput Embedding Pipeline** - Optimized batched processing for maximum efficiency
- **ğŸ¯ Two-level Search** - Novel coarse-to-fine search overlap for accelerated query processing (optional)
- **ğŸ’¾ Memory-mapped Indices** - Fast startup with raw text mapping to reduce memory overhead
- **ğŸš€ MLX Support** - Ultra-fast recompute/build with quantized embedding models, accelerating building and search ([minimal example](../examples/mlx_demo.py))

## ğŸ¨ Developer Experience

- **Simple Python API** - Get started in minutes
- **Extensible backend system** - Easy to add new algorithms
- **Comprehensive examples** - From basic usage to production deployment
